{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55ceaf38-06f1-485c-b99c-71cf28ed99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic | £51.77 | Three\n",
      "Tipping the Velvet | £53.74 | One\n",
      "Soumission | £50.10 | One\n",
      "Sharp Objects | £47.82 | Four\n",
      "Sapiens: A Brief History of Humankind | £54.23 | Five\n",
      "The Requiem Red | £22.65 | One\n",
      "The Dirty Little Secrets of Getting Your Dream Job | £33.34 | Four\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist| Victoria Woodhull | £17.93 | Three\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics | £22.60 | Four\n",
      "The Black Maria | £52.15 | One\n",
      "Starving Hearts (Triangular Trade Trilogy| #1) | £13.99 | Two\n",
      "Shakespeare's Sonnets | £20.66 | Four\n",
      "Set Me Free | £17.46 | Five\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) | £52.29 | Five\n",
      "Rip it Up and Start Again | £35.02 | Five\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground| 1981-1991 | £57.25 | Three\n",
      "Olio | £23.88 | One\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849 | £37.59 | One\n",
      "Libertarianism for Beginners | £51.33 | Two\n",
      "It's Only the Himalayas | £45.17 | Two\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# URL of the page to scrape\n",
    "books_url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "\n",
    "# Add headers to mimic a browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Create a request with headers\n",
    "req = Request(books_url, headers=headers)\n",
    "\n",
    "# Fetch the page content\n",
    "try:\n",
    "    web_client = urlopen(req)\n",
    "    webpage_html = web_client.read()\n",
    "    web_client.close()\n",
    "\n",
    "    # Parse the HTML using BeautifulSoup\n",
    "    parsed_page = bs(webpage_html, \"html.parser\")\n",
    "\n",
    "    # Find the book containers\n",
    "    book_containers = parsed_page.findAll(\"article\", {\"class\": \"product_pod\"})\n",
    "\n",
    "    # Open a file to save the results\n",
    "    file_name = \"books_data.csv\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        # Write headers to the CSV file\n",
    "        file.write(\"Book_Title,Price,Rating\\n\")\n",
    "\n",
    "        # Iterate through each book container\n",
    "        for book in book_containers:\n",
    "            try:\n",
    "                # Extract book title\n",
    "                book_title = book.h3.a[\"title\"]\n",
    "\n",
    "                # Extract price\n",
    "                price = book.find(\"p\", {\"class\": \"price_color\"}).text.strip()\n",
    "\n",
    "                # Extract rating\n",
    "                rating_class = book.p[\"class\"]\n",
    "                rating = rating_class[1]  # The rating is the second class (e.g., 'star-rating Three')\n",
    "\n",
    "                # Write data to the CSV file\n",
    "                file.write(f\"{book_title.replace(',', '|')},{price},{rating}\\n\")\n",
    "\n",
    "                # Print to console for verification\n",
    "                print(f\"{book_title.replace(',', '|')} | {price} | {rating}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any errors during data extraction\n",
    "                print(f\"Error processing book: {e}\")\n",
    "\n",
    "except HTTPError as e:\n",
    "    print(f\"HTTP Error: {e.code}, {e.reason}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "955f99dc-eff2-4ee6-be22-1fbf28710a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f961b-8e3e-4a79-86b3-de29d64c6c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
